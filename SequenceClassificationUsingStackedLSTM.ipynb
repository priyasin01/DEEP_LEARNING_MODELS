{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SequenceClassificationUsingStackedLSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/priyasin01/DEEP_LEARNING_MODELS/blob/master/SequenceClassificationUsingStackedLSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "iIBuJd3YKRKy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKMtGkTGKTij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Stacked LSTM for sequence classification"
      ]
    },
    {
      "metadata": {
        "id": "UMY64X1iKU9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RWXEludsKcUY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this model, we stack 3 LSTM layers on top of each other, making the model capable of learning higher-level temporal representations.\n",
        "\n",
        "The first two LSTMs return their full output sequences, but the last one only returns the last step in its output sequence, thus dropping the temporal dimension (i.e. converting the input sequence into a single vector).\n",
        "\n",
        "stacked LSTM\n",
        "![alt text](https://keras.io/img/regular_stacked_lstm.png)"
      ]
    },
    {
      "metadata": {
        "id": "g0X-2q4KKz5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "330a8a9c-2f0d-4e08-d193-521740e5cb2c"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "WJIJslFXMxCJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "b27e70eb-3197-41f2-fa1a-ede6ffb123b6"
      },
      "cell_type": "code",
      "source": [
        "timesteps=8\n",
        "data_dim=16\n",
        "num_classes=10\n",
        "\n",
        "#input data shape=(batch_size, timsesteps, data_dim)\n",
        "model=Sequential()\n",
        "model.add(LSTM(32, return_sequences=True, input_shape=(timesteps, data_dim))) #returns a sequence of vectors of dimension 32\n",
        "model.add(LSTM(32, return_sequences=True)) #returns a sequence of vectors of dimension 32\n",
        "model.add(LSTM(32)) #returns a single vector of dimension 32\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='rmsprop',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "#generate dummy data for training\n",
        "x_train=np.random.random((1000,timesteps,data_dim))\n",
        "y_train=np.random.random((1000,num_classes))\n",
        "\n",
        "#generate dummy valiation data\n",
        "x_val=np.random.random((100,timesteps,data_dim))\n",
        "y_val=np.random.random((100,num_classes))\n",
        "\n",
        "#generate dummy test data\n",
        "x_test=np.random.random((100,timesteps,data_dim))\n",
        "y_test=np.random.random((100,num_classes))\n",
        "\n",
        "model.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_val,y_val))\n",
        "score=model.evaluate(x_test,y_test,batch_size=64)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 11.6561 - acc: 0.1070 - val_loss: 11.6099 - val_acc: 0.0700\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6548 - acc: 0.0980 - val_loss: 11.6109 - val_acc: 0.1000\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6543 - acc: 0.1120 - val_loss: 11.6105 - val_acc: 0.0700\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6537 - acc: 0.1080 - val_loss: 11.6116 - val_acc: 0.0700\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6536 - acc: 0.1120 - val_loss: 11.6110 - val_acc: 0.0600\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6537 - acc: 0.1050 - val_loss: 11.6122 - val_acc: 0.0500\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6530 - acc: 0.1230 - val_loss: 11.6124 - val_acc: 0.0600\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6531 - acc: 0.1150 - val_loss: 11.6100 - val_acc: 0.0800\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6527 - acc: 0.1170 - val_loss: 11.6108 - val_acc: 0.0900\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 11.6522 - acc: 0.1090 - val_loss: 11.6138 - val_acc: 0.0600\n",
            "100/100 [==============================] - 0s 546us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZEx5Fs3VO7L8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b8262d44-7b43-4377-9a85-d0cd9e2470b9"
      },
      "cell_type": "code",
      "source": [
        "score"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.652985801696778, 0.12000000014901162]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "ZAexkBfHPjD9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}